# -*- coding: utf-8 -*-
"""3. Pelatihan LSTM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q7UkICmSuBOZJyGdjF8tvBRomNKagwP_
"""

import numpy as np
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')

# Membaca Data Pelatihan
def read_train_data(train_data_file):
    # Membaca file data pelatihan
    df = pd.read_excel(train_data_file)
    jml_data = len(df)
    jml_input = len(df.columns) - 8 # Kolom label dan target dihapus dari jumlah input
    jml_output = df['Label'].nunique()  # Jumlah kelas adalah jumlah penulis unik

    print("\nData Pelatihan : ")
    print(df)

    return jml_data, jml_input, jml_output, df

def split_and_create_batch(df, label):
    data_penulis = [df[df[label] == i] for i in range(1, 8)]
    min_length = min(len(data) for data in data_penulis)
    data_batch = []

    for i in range(0, min_length, 5):
        batch = pd.concat([data.iloc[i:i+5] for data in data_penulis])
        data_batch.append(batch)

    for j, batch in enumerate(data_batch):
        print(f"Batch ke-{j+1}:")
        print(batch)
        print("\n")

    return data_batch

# Inisialisasi Parameter LSTM
def parameter(jml_data, jml_input, jml_output):
    # Meminta input dari pengguna untuk parameter-parameter yang diperlukan
    alpha = float(input("Masukkan learning rate (α) (0,1) : "))
    while alpha <= 0 or alpha >= 1:
        print("Nilai alpha harus berada di interval (0,1). Silakan masukkan kembali.")
        alpha = float(input("Masukkan learning rate (α) (0,1) : "))
    min_error = float(input("Masukkan minimum error (>0) : "))
    if min_error <= 0:
        print("Nilai minimum error harus bernilai lebih dari 0. Silakan masukkan kembali.")
        min_error = float(input("Masukkan minimum error (>0) : "))
    max_epoch = int(input("Masukkan maksimum epoch (>0): "))
    if max_epoch <= 0:
        print("Maksimum epoch harus berjumlah lebih dari 0. Silakan masukkan kembali.")
        max_epoch = int(input("Masukkan maksimum epoch (>0): "))
    jml_hidden = 2500

     # Menampilkan Parameter Proses Pelatihan
    print("\n\nParameter Proses Pelatihan")
    print("Learning rate (α)     : ", alpha)
    print("Maksimum epoch        : ", max_epoch)
    print("Minimum error         : ", min_error)
    print("Jumlah input          : ", jml_input)
    print("Jumlah hidden layer   : ", jml_hidden)
    print("Jumlah output         : ", jml_output)
    print("\n")

    return alpha, min_error, max_epoch, jml_hidden

# Membangkitkan Bobot dan Bias LSTM
def rand_bobot(jml_input, jml_hidden, jml_output):
    # Membangkitkan bobot dan bias forget gates
    Wf = np.random.randn(jml_input, jml_hidden) * 0.1
    Uf = np.random.randn(jml_hidden, jml_hidden) * 0.1
    bf = np.random.randn(1, jml_hidden) * 0.1

    # Membangkitkan bobot dan bias input gates
    Wi = np.random.randn(jml_input, jml_hidden) * 0.1
    Ui = np.random.randn(jml_hidden, jml_hidden) * 0.1
    bi = np.random.randn(1, jml_hidden) * 0.1

    # Membangkitkan bobot dan bias kandidat cell state
    Wc = np.random.randn(jml_input, jml_hidden) * 0.1
    Uc = np.random.randn(jml_hidden, jml_hidden) * 0.1
    bc = np.random.randn(1, jml_hidden) * 0.1

    # Membangkitkan bobot dan bias output gates
    Wo = np.random.randn(jml_input, jml_hidden)  * 0.1
    Uo = np.random.randn(jml_hidden, jml_hidden) * 0.1
    bo = np.random.randn(1, jml_hidden) * 0.1

    # Membangkitkan bobot dan bias output layer
    Wy = np.random.randn(jml_hidden, jml_output) * 0.1
    by = np.random.randn(1, jml_output) * 0.1

    print("\nBobot dan Bias Awal : ")
    print("\nWf : ")
    print(Wf)
    print("\nUf : ")
    print(Uf)
    print("\nbf : ")
    print(bf)
    print("\nWi : ")
    print(Wi)
    print("\nUi : ")
    print(Ui)
    print("\nbi : ")
    print(bi)
    print("\nWc : ")
    print(Wc)
    print("\nUc : ")
    print(Uc)
    print("\nbc : ")
    print(bc)
    print("\nWo : ")
    print(Wo)
    print("\nUo : ")
    print(Uo)
    print("\nbo : ")
    print(bo)
    print("\nWy : ")
    print(Wy)
    print("\nby : ")
    print(by)

    return Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by

# Fungsi Aktivasi Sigmoid Biner
def sigm(x):
    return 1 / (1 + np.exp(-x))

# Fungsi Aktivasi Tangent Hyperbolic
def tanh(x):
    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))

# Fungsi Aktivasi Softmax
def softmax(x):
    exp_x = np.exp(x - np.max(x))
    sum_exp_x = np.sum(exp_x)
    softmax = exp_x / (sum_exp_x)

    return softmax

def ins_hidd_cell_awal(jml_hidden):
    h_prev = np.zeros((1, jml_hidden))
    C_prev = np.zeros((1, jml_hidden))

    print("\nNilai h(t-1) dan C(t-1) Awal Proses Pelatihan : ")
    print("\nh(t-1) : ")
    print(h_prev)
    print("\nC(t-1) : ")
    print(C_prev)

    return h_prev, C_prev

def feedforward_lstm(Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by, h_prev, C_prev, batch):
    f_list = []
    i_list = []
    kC_list = []
    C_list = []
    o_list = []
    h_list = []
    yin_list = []
    y_list = []
    h_prev_list = [h_prev]
    C_prev_list = [C_prev]

    data_latih = batch.iloc[:, :2500].to_numpy()
    for t in range(len(data_latih)):
        f = sigm(np.dot(data_latih[t], Wf) + np.dot(h_prev, Uf) + bf)
        f_list.append(f)
        i = sigm(np.dot(data_latih[t], Wi) + np.dot(h_prev, Ui) + bi)
        i_list.append(i)
        kC = np.tanh(np.dot(data_latih[t], Wc) + np.dot(h_prev, Uc) + bc)
        kC_list.append(kC)
        C = (C_prev * f) + (kC * i)
        C_list.append(C)
        o = sigm(np.dot(data_latih[t], Wo) + np.dot(h_prev, Uo) + bo)
        o_list.append(o)
        h = o * np.tanh(C)
        h_list.append(h)
        yin = np.dot(h, Wy) + by
        yin_list.append(yin)
        y = softmax(yin)
        y_list.append(y)

        h_prev = h
        h_prev_list.append(h_prev)
        C_prev = C
        C_prev_list.append(C_prev)

    return f_list, i_list, kC_list, C_list, o_list, h_list, yin_list, y_list, h_prev_list, C_prev_list

def error(batch, y_list):
    target_latih = batch.iloc[:, 2501:].to_numpy()
    y = np.array(y_list)

    E = 0
    for t in range (len(target_latih)):
        diff = target_latih[t] - y[t]
        square_diff = np.square(diff)
        E += np.sum(square_diff)
    MSE = E / (len(target_latih))

    return MSE

def backpropagation(batch, f_list, i_list, kC_list, C_list, o_list, h_list, y_list, h_prev_list, C_prev_list, Wy, by, Wo,Uo, bo, Wc, Uc, bc, Wi, Ui, bi, Wf, Uf, bf):
    data_latih = batch.iloc[:, :2500].to_numpy()
    target_latih = batch.iloc[:, 2501:].to_numpy()

    dWy = np.zeros_like(Wy)
    dby = np.zeros_like(by)
    dWo = np.zeros_like(Wo)
    dUo = np.zeros_like(Uo)
    dbo = np.zeros_like(bo)
    dWc = np.zeros_like(Wc)
    dUc = np.zeros_like(Uc)
    dbc = np.zeros_like(bc)
    dWi = np.zeros_like(Wi)
    dUi = np.zeros_like(Ui)
    dbi = np.zeros_like(bi)
    dWf = np.zeros_like(Wf)
    dUf = np.zeros_like(Uf)
    dbf = np.zeros_like(bf)
    f = np.array(f_list)
    i = np.array(i_list)
    kC = np.array(kC_list)
    C = np.array(C_list)
    o = np.array(o_list)
    h = np.array(h_list)
    y = np.array(y_list)
    h_prev = np.array(h_prev_list)
    C_prev = np.array(C_prev_list)

    for t in range(len(data_latih)):
        dy = (y[t] - target_latih[t])
        dWy += np.dot(h[t].T, dy)
        dby += dy
        delta_o = ((((np.dot(dy, Wy.T)) * tanh(C[t])) * o[t]) * (1 - o[t]))
        dWo += np.dot(data_latih[t, np.newaxis].T, delta_o)
        dUo += np.dot(delta_o.T, h_prev[t])
        dbo += delta_o
        delta_c = (((((np.dot(dy, Wy.T)) * o[t]) * (1 - (np.square(tanh(C[t]))))) * i[t]) * (1 - (np.square(kC[t]))))
        dWc += np.dot(data_latih[t, np.newaxis].T, delta_c)
        dUc += np.dot(delta_c.T, h_prev[t])
        dbc += delta_c
        delta_i = ((((((np.dot(dy, Wy.T)) * o[t]) * (1 - (np.square(tanh(C[t]))))) * kC[t]) * i[t]) * (1 - i[t]))
        dWi += np.dot(data_latih[t, np.newaxis].T, delta_i)
        dUi += np.dot(delta_i.T, h_prev[t])
        dbi += delta_i
        delta_f = ((((((np.dot(dy, Wy.T)) * o[t]) * (1 - (np.square(tanh(C[t]))))) * C_prev[t]) * f[t]) * (1 - f[t]))
        dWf += np.dot(data_latih[t, np.newaxis].T, delta_f)
        dUf += np.dot(delta_f.T, h_prev[t])
        dbf += delta_f

    return dWy, dby, dWo, dUo, dbo, dWc, dUc, dbc, dWi, dUi, dbi, dWf, dUf, dbf

def update_bobot_bias (alpha, Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by, dWy, dby, dWo, dUo, dbo, dWc, dUc, dbc, dWi, dUi, dbi, dWf, dUf, dbf):
    Wy_b = np.zeros_like(Wy)
    by_b = np.zeros_like(by)
    Uo_b = np.zeros_like(Uo)
    bo_b = np.zeros_like(bo)
    Wo_b = np.zeros_like(Wo)
    Uc_b = np.zeros_like(Uc)
    bc_b = np.zeros_like(bc)
    Wc_b = np.zeros_like(Wc)
    Ui_b = np.zeros_like(Ui)
    bi_b = np.zeros_like(bi)
    Wi_b = np.zeros_like(Wi)
    Uf_b = np.zeros_like(Uf)
    bf_b = np.zeros_like(bf)
    Wf_b = np.zeros_like(Wf)

    Wy_b = Wy - (alpha * dWy)
    by_b = by - (alpha * dby)
    Wo_b = Wo - (alpha * dWo)
    Uo_b = Uo - (alpha * dUo)
    bo_b = bo - (alpha * dbo)
    Wc_b = Wc - (alpha * dWc)
    Uc_b = Uc - (alpha * dUc)
    bc_b = bc - (alpha * dbc)
    Wi_b = Wi - (alpha * dWi)
    Ui_b = Ui - (alpha * dUi)
    bi_b = bi - (alpha * dbi)
    Wf_b = Wf - (alpha * dWf)
    Uf_b = Uf - (alpha * dUf)
    bf_b = bf - (alpha * dbf)

    Wy = Wy_b
    by = by_b
    Wo = Wo_b
    Uo = Uo_b
    bo = bo_b
    Wc = Wc_b
    Uc = Uc_b
    bc = bc_b
    Wi = Wi_b
    Ui = Ui_b
    bi = bi_b
    Wf = Wf_b
    Uf = Uf_b
    bf = bf_b

    return Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by

def save_weights_biases(filename, Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by):
    np.savez(filename, Wf=Wf, Uf=Uf, bf=bf, Wi=Wi, Ui=Ui, bi=bi,
             Wc=Wc, Uc=Uc, bc=bc, Wo=Wo, Uo=Uo, bo=bo, Wy=Wy, by=by)
    print(f"Bobot dan bias disimpan dalam file {filename}")

if __name__ == "__main__":
    train_data_file = '/content/drive/My Drive/Skripsi/Output/Data/data pelatihan.xlsx'

jml_data, jml_input, jml_output, df = read_train_data(train_data_file)

label = 'Label'
    data_batch = split_and_create_batch(df, label)

alpha, min_error, max_epoch, jml_hidden = parameter(jml_data, jml_input, jml_output)

Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by = rand_bobot(jml_input, jml_hidden, jml_output)

h_prev, C_prev = ins_hidd_cell_awal(jml_hidden)

MSE = float('inf')
    error_list = []
    for epoch in range(max_epoch):
      total_error = 0
      for batch in data_batch:
          f_list, i_list, kC_list, C_list, o_list, h_list, yin_list, y_list, h_prev_list, C_prev_list = feedforward_lstm(Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by, h_prev, C_prev, batch)
          MSE = error(batch, y_list)
          error_list.append(MSE)
          dWy, dby, dWo, dUo, dbo, dWc, dUc, dbc, dWi, dUi, dbi, dWf, dUf, dbf = backpropagation(batch, f_list, i_list, kC_list, C_list, o_list, h_list, y_list, h_prev_list, C_prev_list, Wy, by, Wo, Uo, bo, Wc, Uc, bc, Wi, Ui, bi, Wf, Uf, bf)
          Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by = update_bobot_bias(alpha, Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by, dWy, dby, dWo, dUo, dbo, dWc, dUc, dbc, dWi, dUi, dbi, dWf, dUf, dbf)
          total_error

      if MSE <= min_error:
          break
      print(f"Error pada epoch ke-{epoch}: {MSE}")

    print(f"Proses Training selesai pada epoch ke-{epoch} dengan nilai error MSE = {MSE}")

save_weights_biases('/content/drive/My Drive/Skripsi/Output/Pelatihan/bobotbiasoptimal3.npz', Wf, Uf, bf, Wi, Ui, bi, Wc, Uc, bc, Wo, Uo, bo, Wy, by)

print("\n\nUji Validasi Data Pelatihan")
    df_train = pd.read_excel(train_data_file)
    data_latih = df_train.iloc[:, :2500].to_numpy()
    target_latih = df_train.iloc[:, 2501:].to_numpy()
    h_prev_train, C_prev_train = np.zeros((1, jml_hidden)), np.zeros((1, jml_hidden))
    y_pred_train = []
    total_error = 0
    for t in range(len(data_latih)):
        f_train = sigm(np.dot(data_latih[t], Wf) + np.dot(h_prev_train, Uf) + bf)
        i_train = sigm(np.dot(data_latih[t], Wi) + np.dot(h_prev_train, Ui) + bi)
        kC_train = np.tanh(np.dot(data_latih[t], Wc) + np.dot(h_prev_train, Uc) + bc)
        C_train = (C_prev_train * f_train) + (kC_train * i_train)
        o_train = sigm(np.dot(data_latih[t], Wo) + np.dot(h_prev_train, Uo) + bo)
        h_train = o_train * np.tanh(C_train)
        yin_train = np.dot(h_train, Wy) + by
        y_train = softmax(yin_train)
        h_prev_train = h_train
        C_prev_train = C_train
        y_pred_train.append(y_train)

    for t in range(len(data_latih)):
        e = np.mean((target_latih[t] - y_pred_train[t])**2)
        total_error += e
        mse = e / (len(data_latih))
    print("Error Uji Validasi Data Pelatihan: ", mse)

    print("\nPerbandingan Label Prediksi dan Sebenarnya dalam bentuk tabel:")
    comparison_table = pd.DataFrame({
        "Label Prediksi": [np.argmax(pred) + 1 for pred in y_pred_train],
        "Label Sebenarnya": [np.argmax(target) + 1 for target in target_latih]
    })
    print(comparison_table)

    jumlah_benar = sum([1 for i in range(len(target_latih)) if np.argmax(y_pred_train[i]) == np.argmax(target_latih[i])])
    akurasi = jumlah_benar / len(target_latih) * 100
    print(f"Tingkat Akurasi: {akurasi:.2f}%")

print("\n\nProses Pengujian Data Pengujian")
    test_data_file = '/content/drive/My Drive/Skripsi/Output/Data/data pengujian.xlsx'
    df_test = pd.read_excel(test_data_file)
    print("Data yang digunakan untuk pengujian:")
    print(df_test)
    print("\n")

    data_uji = df_test.iloc[:, :2500].to_numpy()
    target_uji = df_test.iloc[:, 2501:].to_numpy()
    h_prev_test, C_prev_test = np.zeros((1, jml_hidden)), np.zeros((1, jml_hidden))
    y_pred_test = []
    total_error_test = 0

    for t in range(len(data_uji)):
        f_test = sigm(np.dot(data_uji[t], Wf) + np.dot(h_prev_test, Uf) + bf)
        i_test = sigm(np.dot(data_uji[t], Wi) + np.dot(h_prev_test, Ui) + bi)
        kC_test = np.tanh(np.dot(data_uji[t], Wc) + np.dot(h_prev_test, Uc) + bc)
        C_test = (C_prev_test * f_test) + (kC_test * i_test)
        o_test = sigm(np.dot(data_uji[t], Wo) + np.dot(h_prev_test, Uo) + bo)
        h_test = o_test * np.tanh(C_test)
        yin_test = np.dot(h_test, Wy) + by
        y_test = softmax(yin_test)

        h_prev_test = h_test
        C_prev_test = C_test
        y_pred_test.append(y_test)

    # Menghitung error setelah semua data selesai diproses
    for t in range(len(data_uji)):
        E_test = np.mean((target_uji[t] - y_pred_test[t])**2)
        total_error_test += E_test
        MSE_test = E_test / (len(data_uji))

    print("Error Pengujian: ", MSE_test)

    # Menampilkan perbandingan target sebenarnya dan target prediksi dalam bentuk tabel
    print("\nPerbandingan Label Prediksi dan Sebenarnya dalam bentuk tabel:")
    comparison_table = pd.DataFrame({
        "Iterasi": range(1, len(data_uji) + 1),
        "Label Prediksi": [np.argmax(pred) for pred in y_pred_test],
        "Label Sebenarnya": [np.argmax(target) for target in target_uji]
    })
    print(comparison_table)

    # Menghitung dan menampilkan tingkat akurasi
    jumlah_benar = sum([1 for i in range(len(target_uji)) if np.argmax(y_pred_test[i]) == np.argmax(target_uji[i])])
    akurasi = jumlah_benar / len(target_uji) * 100
    print(f"Tingkat Akurasi: {akurasi:.2f}%")